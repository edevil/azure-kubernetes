#cloud-config
coreos:
  update:
    reboot-strategy: "off"
  etcd2:
    name: controller
    data-dir: "/mnt/etcd"    
    advertise-client-urls: http://$private_ipv4:2379
    initial-advertise-peer-urls: http://$private_ipv4:2380
    listen-client-urls: http://0.0.0.0:2379
    listen-peer-urls: http://0.0.0.0:2380
    initial-cluster: controller=http://$private_ipv4:2380
  units:
    - name: update-engine.service
      command: stop
    - name: locksmithd.service
      command: stop
    - name: "format-etcd-disk.service"
      command: "start"
      content: |
        [Unit]
        Description=Formats the data-disk if it is not forwatted
        [Service]
        Type=oneshot
        RemainAfterExit=yes
        ExecStart=/usr/bin/sh -c "if lsblk --output=FSTYPE /dev/sdc | grep btrfs > /tmp/dum;then echo ok;else /usr/sbin/wipefs -f /dev/sdc;/usr/sbin/mkfs.btrfs -f /dev/sdc; fi"
    - name: "mnt-etcd.mount"
      command: "start"
      content: |
        [Unit]
        Description=Mount disk to /mnt/etcd
        Requires=format-etcd-disk.service
        After=format-etcd-disk.service
        Before=prepare-etcd-dir.service
        [Mount]
        What=/dev/sdc
        Where="/mnt/etcd"
        Type=btrfs
    - name: "prepare-etcd-dir.service"    
      command: start
      content: |
        [Unit]
        Description=Prepares the etcd data directory
        Requires=mnt-etcd.mount
        After=mnt-etcd.mount
        Before=etcd2.service
        [Service]
        Type=oneshot
        RemainAfterExit=yes
        ExecStart=/usr/bin/chown -R etcd:etcd /mnt/etcd
    - name: "etcd2.service"
      command: "start"
      drop-ins:
      - name: 30-storage-mount.conf
        content: |
          [Unit]
          After=prepare-etcd-dir.service
          Requires=prepare-etcd-dir.service
    - name: "docker.service"
      drop-ins:
        - name: 50-docker-opts.conf
          content: |
            [Service]
            Environment='DOCKER_OPTS=--bridge=cbr0 --iptables=false --ip-masq=false'
            MountFlags=slave
            LimitNOFILE=1048576
            LimitNPROC=1048576
            LimitCORE=infinity
            Restart=always
            RestartSec=2s
            StartLimitInterval=0

    - name: "kubelet.service"
      command: start
      content: |
        [Unit]
        After=install-kubernetes.service
        ConditionFileIsExecutable=/opt/kubernetes/server/bin/kubelet
        Description=Kubernetes Kubelet
        Wants=install-kubernetes.service
        [Service]
        ExecStartPre=/bin/mkdir -p /etc/kubernetes/manifests/
        ExecStart=/opt/kubernetes/server/bin/kubelet \
            --api-servers=http://localhost:8080 \
            --register-schedulable=false \
            --allow-privileged=true \
            --configure-cbr0=true \
            --reconcile-cidr=false \
            --pod-cidr=${kubePodCidr} \
            --container-runtime=docker \
            --config=/etc/kubernetes/manifests/ \
            --cluster-dns=${kubeDnsServiceIP} \
            --cluster-domain=cluster.local \
            --logtostderr=true
        Restart=always
        RestartSec=10
        [Install]
        WantedBy=multi-user.target

    - name: "install-kubernetes.service"
      command: start
      content: |
        [Unit]
        After=network-online.target
        Before=kubelet.service
        Description=Download Kubernetes Binaries
        Documentation=http://kubernetes.io/
        Requires=network-online.target
        [Service]
        Environment=KUBE_RELEASE_TARBALL=https://storage.googleapis.com/kubernetes-release/release/${k8sVer}/kubernetes.tar.gz
        ExecStartPre=/bin/mkdir -p /opt/
        ExecStart=/opt/bin/curl-retry.sh --silent --location $KUBE_RELEASE_TARBALL --output /tmp/kubernetes.tgz
        ExecStart=/bin/tar xzvf /tmp/kubernetes.tgz -C /tmp/
        ExecStart=/bin/tar xzvf /tmp/kubernetes/server/kubernetes-server-linux-amd64.tar.gz -C /opt  --overwrite
        ExecStartPost=/bin/chmod o+rx -R /opt/kubernetes
        ExecStartPost=/bin/ln -sf /opt/kubernetes/server/bin/kubectl /opt/bin/
        ExecStartPost=/bin/rm -rf /tmp/kubernetes
        RemainAfterExit=yes
        Type=oneshot
        [Install]
        WantedBy=kubelet.service

    - name: "install-kube-system.service"
      command: start
      content: |
        [Unit]
        Requires=kubelet.service docker.service
        After=kubelet.service docker.service
        [Service]
        Type=simple
        StartLimitInterval=0
        Restart=on-failure
        ExecStartPre=/usr/bin/curl http://127.0.0.1:8080/version
        ExecStart=/opt/bin/install-kube-system

write_files:
  - path: /etc/kubernetes/azure/auth.json
    permissions: "0644"
    owner: "root"
    content: |
      {
          "tenantId": "${tenantId}",
          "subscriptionId": "${subscriptionId}",
          "resourceGroup": "${resourceGroup}",
          "servicePrincipalClientId": "${servicePrincipalClientId}",
          "servicePrincipalClientSecret": "${servicePrincipalClientSecret}"
      }

  - path: /opt/bin/install-kube-system
    permissions: 0700
    owner: root:root
    content: |
      #!/bin/bash -e
      /usr/bin/curl -H "Content-Type: application/json" -XPOST -d @"/srv/kubernetes/manifests/kube-system.json" "http://127.0.0.1:8080/api/v1/namespaces"

      /usr/bin/curl  -H "Content-Type: application/json" -XPOST \
      -d @"/srv/kubernetes/manifests/kube-dns-rc.json" \
      "http://127.0.0.1:8080/api/v1/namespaces/kube-system/replicationcontrollers"

      /usr/bin/curl  -H "Content-Type: application/json" -XPOST \
      -d @"/srv/kubernetes/manifests/heapster-dc.json" \
      "http://127.0.0.1:8080/apis/extensions/v1beta1/namespaces/kube-system/deployments"

      for manifest in {kube-dns,heapster}-svc.json;do
          /usr/bin/curl  -H "Content-Type: application/json" -XPOST \
          -d @"/srv/kubernetes/manifests/$manifest" \
          "http://127.0.0.1:8080/api/v1/namespaces/kube-system/services"
      done
      
  - path: /etc/kubernetes/manifests/kube-proxy.yaml
    content: |
        apiVersion: v1
        kind: Pod
        metadata:
          name: kube-proxy
          namespace: kube-system
        spec:
          hostNetwork: true
          containers:
          - name: kube-proxy
            image: ${hyperkubeImage}
            command:
            - /hyperkube
            - proxy
            - --master=http://127.0.0.1:8080
            - --proxy-mode=iptables
            securityContext:
              privileged: true
            volumeMounts:
            - mountPath: /etc/ssl/certs
              name: ssl-certs-host
              readOnly: true
          volumes:
          - hostPath:
              path: /usr/share/ca-certificates
            name: ssl-certs-host

  - path: /etc/kubernetes/manifests/kube-apiserver.yaml
    content: |
      apiVersion: v1
      kind: Pod
      metadata:
        name: kube-apiserver
        namespace: kube-system
      spec:
        hostNetwork: true
        containers:
        - name: kube-apiserver
          image: ${hyperkubeImage}
          command:
          - /hyperkube
          - apiserver
          - --bind-address=0.0.0.0
          - --etcd-servers=${ETCDEndpoints}
          - --allow-privileged=true
          - --service-cluster-ip-range=${kubeServiceCidr}
          - --secure-port=6443
          - --advertise-address=$private_ipv4
          - --admission-control=NamespaceLifecycle,LimitRanger,ServiceAccount,ResourceQuota
          - --tls-cert-file=/etc/kubernetes/ssl/apiserver.pem
          - --tls-private-key-file=/etc/kubernetes/ssl/apiserver-key.pem
          - --client-ca-file=/etc/kubernetes/ssl/ca.pem
          - --service-account-key-file=/etc/kubernetes/ssl/apiserver-key.pem
          - --runtime-config=extensions/v1beta1/deployments=true,extensions/v1beta1/daemonsets=true,extensions/v1beta1=true,extensions/v1beta1/thirdpartyresources=true
          ports:
          - containerPort: 6443
            hostPort: 6443
            name: https
          - containerPort: 8080
            hostPort: 8080
            name: local
          volumeMounts:
          - mountPath: /etc/kubernetes/ssl
            name: ssl-certs-kubernetes
            readOnly: true
          - mountPath: /etc/ssl/certs
            name: ssl-certs-host
            readOnly: true
        volumes:
        - hostPath:
            path: /etc/kubernetes/ssl
          name: ssl-certs-kubernetes
        - hostPath:
            path: /usr/share/ca-certificates
          name: ssl-certs-host

  - path: /etc/kubernetes/manifests/kube-controller-manager.yaml
    content: |
      apiVersion: v1
      kind: Pod
      metadata:
        name: kube-controller-manager
        namespace: kube-system
      spec:
        containers:
        - name: kube-controller-manager
          image: ${hyperkubeImage}
          command:
          - /hyperkube
          - controller-manager
          - --master=http://127.0.0.1:8080
          - --cluster-name=${resourceGroup}
          - --cluster-cidr=${kubeClusterCidr}
          - --service-account-private-key-file=/etc/kubernetes/ssl/apiserver-key.pem
          - --root-ca-file=/etc/kubernetes/ssl/ca.pem
          livenessProbe:
            httpGet:
              host: 127.0.0.1
              path: /healthz
              port: 10252
            initialDelaySeconds: 15
            timeoutSeconds: 1
          volumeMounts:
          - mountPath: /etc/kubernetes/ssl
            name: ssl-certs-kubernetes
            readOnly: true
          - mountPath: /etc/ssl/certs
            name: ssl-certs-host
            readOnly: true
        hostNetwork: true
        volumes:
        - hostPath:
            path: /etc/kubernetes/ssl
          name: ssl-certs-kubernetes
        - hostPath:
            path: /usr/share/ca-certificates
          name: ssl-certs-host

  - path: /etc/kubernetes/manifests/kube-scheduler.yaml
    content: |
      apiVersion: v1
      kind: Pod
      metadata:
        name: kube-scheduler
        namespace: kube-system
      spec:
        hostNetwork: true
        containers:
        - name: kube-scheduler
          image: ${hyperkubeImage}
          command:
          - /hyperkube
          - scheduler
          - --master=http://127.0.0.1:8080
          - --leader-elect=true
          livenessProbe:
            httpGet:
              host: 127.0.0.1
              path: /healthz
              port: 10251
            initialDelaySeconds: 15
            timeoutSeconds: 1

  - path: /srv/kubernetes/manifests/kube-system.json
    content: |
        {
          "apiVersion": "v1",
          "kind": "Namespace",
          "metadata": {
            "name": "kube-system"
          }
        }

  - path: /srv/kubernetes/manifests/kube-dns-rc.json
    content: |
        {
          "apiVersion": "v1",
          "kind": "ReplicationController",
          "metadata": {
            "labels": {
              "k8s-app": "kube-dns",
              "kubernetes.io/cluster-service": "true",
              "version": "v11"
            },
            "name": "kube-dns-v11",
            "namespace": "kube-system"
          },
          "spec": {
            "replicas": 1,
            "selector": {
              "k8s-app": "kube-dns",
              "version": "v11"
            },
            "template": {
              "metadata": {
                "labels": {
                  "k8s-app": "kube-dns",
                  "kubernetes.io/cluster-service": "true",
                  "version": "v11"
                }
              },
              "spec": {
                "containers": [
                  {
                    "command": [
                      "/usr/local/bin/etcd",
                      "-data-dir",
                      "/var/etcd/data",
                      "-listen-client-urls",
                      "http://127.0.0.1:2379,http://127.0.0.1:4001",
                      "-advertise-client-urls",
                      "http://127.0.0.1:2379,http://127.0.0.1:4001",
                      "-initial-cluster-token",
                      "skydns-etcd"
                    ],
                    "image": "gcr.io/google_containers/etcd-amd64:2.2.1",
                    "name": "etcd",
                    "resources": {
                      "limits": {
                        "cpu": "100m",
                        "memory": "500Mi"
                      },
                      "requests": {
                        "cpu": "100m",
                        "memory": "50Mi"
                      }
                    },
                    "volumeMounts": [
                      {
                        "mountPath": "/var/etcd/data",
                        "name": "etcd-storage"
                      }
                    ]
                  },
                  {
                    "args": [
                      "--domain=cluster.local"
                    ],
                    "image": "gcr.io/google_containers/kube2sky:1.14",
                    "livenessProbe": {
                      "failureThreshold": 5,
                      "httpGet": {
                        "path": "/healthz",
                        "port": 8080,
                        "scheme": "HTTP"
                      },
                      "initialDelaySeconds": 60,
                      "successThreshold": 1,
                      "timeoutSeconds": 5
                    },
                    "name": "kube2sky",
                    "readinessProbe": {
                      "httpGet": {
                        "path": "/readiness",
                        "port": 8081,
                        "scheme": "HTTP"
                      },
                      "initialDelaySeconds": 30,
                      "timeoutSeconds": 5
                    },
                    "resources": {
                      "limits": {
                        "cpu": "100m",
                        "memory": "200Mi"
                      },
                      "requests": {
                        "cpu": "100m",
                        "memory": "50Mi"
                      }
                    }
                  },
                  {
                    "args": [
                      "-machines=http://127.0.0.1:4001",
                      "-addr=0.0.0.0:53",
                      "-ns-rotate=false",
                      "-domain=cluster.local."
                    ],
                    "image": "gcr.io/google_containers/skydns:2015-10-13-8c72f8c",
                    "name": "skydns",
                    "ports": [
                      {
                        "containerPort": 53,
                        "name": "dns",
                        "protocol": "UDP"
                      },
                      {
                        "containerPort": 53,
                        "name": "dns-tcp",
                        "protocol": "TCP"
                      }
                    ],
                    "resources": {
                      "limits": {
                        "cpu": "100m",
                        "memory": "200Mi"
                      },
                      "requests": {
                        "cpu": "100m",
                        "memory": "50Mi"
                      }
                    }
                  },
                  {
                    "args": [
                      "-cmd=nslookup kubernetes.default.svc.cluster.local 127.0.0.1 >/dev/null",
                      "-port=8080"
                    ],
                    "image": "gcr.io/google_containers/exechealthz:1.0",
                    "name": "healthz",
                    "ports": [
                      {
                        "containerPort": 8080,
                        "protocol": "TCP"
                      }
                    ],
                    "resources": {
                      "limits": {
                        "cpu": "10m",
                        "memory": "20Mi"
                      },
                      "requests": {
                        "cpu": "10m",
                        "memory": "20Mi"
                      }
                    }
                  }
                ],
                "dnsPolicy": "Default",
                "volumes": [
                  {
                    "emptyDir": {},
                    "name": "etcd-storage"
                  }
                ]
              }
            }
          }
        }

  - path: /srv/kubernetes/manifests/kube-dns-svc.json
    content: |
        {
          "apiVersion": "v1",
          "kind": "Service",
          "metadata": {
            "name": "kube-dns",
            "namespace": "kube-system",
            "labels": {
              "k8s-app": "kube-dns",
              "kubernetes.io/name": "KubeDNS",
              "kubernetes.io/cluster-service": "true"
            }
          },
          "spec": {
            "clusterIP": "${kubeDnsServiceIP}",
            "ports": [
              {
                "protocol": "UDP",
                "name": "dns",
                "port": 53
              },
              {
                "protocol": "TCP",
                "name": "dns-tcp",
                "port": 53
              }
            ],
            "selector": {
              "k8s-app": "kube-dns"
            }
          }
        }

  - path: /srv/kubernetes/manifests/heapster-dc.json
    content: |
        {
          "apiVersion": "extensions/v1beta1",
          "kind": "Deployment",
          "metadata": {
            "labels": {
              "k8s-app": "heapster",
              "kubernetes.io/cluster-service": "true",
              "version": "v1.0.2"
            },
            "name": "heapster-v1.0.2",
            "namespace": "kube-system"
          },
          "spec": {
            "replicas": 1,
            "selector": {
              "matchLabels": {
                "k8s-app": "heapster",
                "version": "v1.0.2"
              }
            },
            "template": {
              "metadata": {
                "labels": {
                  "k8s-app": "heapster",
                  "version": "v1.0.2"
                }
              },
              "spec": {
                "containers": [
                  {
                    "command": [
                      "/heapster",
                      "--source=kubernetes.summary_api:''",
                      "--metric_resolution=60s"
                    ],
                    "image": "gcr.io/google_containers/heapster:v1.0.2",
                    "name": "heapster",
                    "resources": {
                      "limits": {
                        "cpu": "100m",
                        "memory": "250Mi"
                      },
                      "requests": {
                        "cpu": "100m",
                        "memory": "250Mi"
                      }
                    }
                  },
                  {
                    "command": [
                      "/pod_nanny",
                      "--cpu=100m",
                      "--extra-cpu=0m",
                      "--memory=250Mi",
                      "--extra-memory=4Mi",
                      "--threshold=5",
                      "--deployment=heapster-v1.0.2",
                      "--container=heapster",
                      "--poll-period=300000"
                    ],
                    "env": [
                      {
                        "name": "MY_POD_NAME",
                        "valueFrom": {
                          "fieldRef": {
                            "fieldPath": "metadata.name"
                          }
                        }
                      },
                      {
                        "name": "MY_POD_NAMESPACE",
                        "valueFrom": {
                          "fieldRef": {
                            "fieldPath": "metadata.namespace"
                          }
                        }
                      }
                    ],
                    "image": "gcr.io/google_containers/addon-resizer:1.0",
                    "name": "heapster-nanny",
                    "resources": {
                      "limits": {
                        "cpu": "50m",
                        "memory": "100Mi"
                      },
                      "requests": {
                        "cpu": "50m",
                        "memory": "100Mi"
                      }
                    }
                  }
                ]
              }
            }
          }
        }

  - path: /srv/kubernetes/manifests/heapster-svc.json
    content: |
        {
          "kind": "Service",
          "apiVersion": "v1",
          "metadata": {
            "name": "heapster",
            "namespace": "kube-system",
            "labels": {
              "kubernetes.io/cluster-service": "true",
              "kubernetes.io/name": "Heapster"
            }
          },
          "spec": {
            "ports": [
              {
                "port": 80,
                "targetPort": 8082
              }
            ],
            "selector": {
              "k8s-app": "heapster"
            }
          }
        }
 
  - path: /etc/kubernetes/ssl/ca.pem
    permissions: "0644"
    encoding: "base64"
    owner: "root"
    content: |
      ${caCertificate}
  - path: /etc/kubernetes/ssl/apiserver.pem
    permissions: "0644"
    encoding: "base64"
    owner: "root"
    content: |
      ${apiserverCertificate}
  - path: /etc/kubernetes/ssl/apiserver-key.pem
    permissions: "0644"
    encoding: "base64"
    owner: "root"
    content: |
      ${apiserverPrivateKey}
  - path: /etc/kubernetes/ssl/client.crt
    permissions: "0644"
    encoding: "base64"
    owner: "root"
    content: |
      ${clientCertificate}
  - path: /etc/kubernetes/ssl/client.key
    permissions: "0644"
    encoding: "base64"
    owner: "root"
    content: |
      ${clientPrivateKey}
  - path: "/var/lib/kubelet/kubeconfig"
    permissions: "0644"
    owner: "root"
    content: |
      apiVersion: v1
      kind: Config
      clusters:
      - name: localcluster
        cluster:
          certificate-authority: /etc/kubernetes/ssl/ca.pem
          server: https://${masterPrivateIp}:6443
      users:
      - name: client
        user:
          client-certificate: /etc/kubernetes/ssl/client.crt
          client-key: /etc/kubernetes/ssl/client.key
      contexts:
      - context:
          cluster: localcluster
          user: client
        name: localclustercontext
      current-context: localclustercontext
      
  - path: /opt/bin/curl-retry.sh
    permissions: '0755'
    owner: root
    content: |
      #!/bin/sh -x
      until curl $@
      do sleep 1
      done      